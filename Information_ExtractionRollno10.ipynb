{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " Information ExtractionRollno10.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CF7CvVhRNKt4"
      },
      "source": [
        "\n",
        "\n",
        "Information Extraction: \n",
        "1. Part-of-Speech Tagging\n",
        "2. Chunking\n",
        "3. Chinking\n",
        "4. Named Entity Recognition\n",
        "5. Relation Extraction\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaUKmeZRNhYD"
      },
      "source": [
        "1. Part-of-Speech Tagging\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jjxtqjwMSA6",
        "outputId": "ab431651-2f49-49b7-f981-4067ec133409"
      },
      "source": [
        "import nltk\n",
        "import string\n",
        "import re\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag\n",
        "from nltk.tokenize.regexp import WhitespaceTokenizer\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "def pos_tagging(text):\n",
        " word_tokens = word_tokenize(text)\n",
        " return pos_tag(word_tokens) \n",
        "  \n",
        "pos_tagging('You just gave me a scare')"
      ],
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('You', 'PRP'),\n",
              " ('just', 'RB'),\n",
              " ('gave', 'VBD'),\n",
              " ('me', 'PRP'),\n",
              " ('a', 'DT'),\n",
              " ('scare', 'NN')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHagWY_pWDx3"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQvP95CpM_7i",
        "outputId": "5dd15170-8e00-4666-904e-64ad04fc704f"
      },
      "source": [
        "nltk.download('tagsets')"
      ],
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]   Package tagsets is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 189
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xK8jQ-tPNB8a",
        "outputId": "57381475-f7c2-45fe-c568-8dcdaa77c80c"
      },
      "source": [
        "nltk.help.upenn_tagset('NN')\n"
      ],
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NN: noun, common, singular or mass\n",
            "    common-carrier cabbage knuckle-duster Casino afghan shed thermostat\n",
            "    investment slide humour falloff slick wind hyena override subhumanity\n",
            "    machinist ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrwPzj5qNl1d"
      },
      "source": [
        "2. Chunking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WlCuFnfXNsJt",
        "outputId": "2b3e8929-ebbd-49b5-bfb2-869effdc05a2"
      },
      "source": [
        "locs = [('Omnicom', 'IN', 'New York'),\n",
        "...         ('DDB Needham', 'IN', 'New York'),\n",
        "...         ('Kaplan Thaler Group', 'IN', 'New York'),\n",
        "...         ('BBDO South', 'IN', 'Atlanta'),\n",
        "...         ('Georgia-Pacific', 'IN', 'Atlanta')]\n",
        "query = [e1 for (e1, rel, e2) in locs if e2=='Atlanta']\n",
        "print(query)\n",
        "\n",
        "def ie_preprocess(document):\n",
        "...    sentences = nltk.sent_tokenize(document) \n",
        "...    sentences = [nltk.word_tokenize(sent) for sent in sentences]\n",
        "...    sentences = [nltk.pos_tag(sent) for sent in sentences] \n",
        "\n",
        "sentence = [(\"the\", \"DT\"), (\"little\", \"JJ\"), (\"yellow\", \"JJ\"),\n",
        "... (\"dog\", \"NN\"), (\"barked\", \"VBD\"), (\"at\", \"IN\"),  (\"the\", \"DT\"), (\"cat\", \"NN\")]\n",
        "grammar = \"NP: {<DT>?<JJ>*<NN>}\"\n",
        "cp = nltk.RegexpParser(grammar)\n",
        "result = cp.parse(sentence)\n",
        "print(result)\n"
      ],
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['BBDO South', 'Georgia-Pacific']\n",
            "(S\n",
            "  (NP the/DT little/JJ yellow/JJ dog/NN)\n",
            "  barked/VBD\n",
            "  at/IN\n",
            "  (NP the/DT cat/NN))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsaHRAy0NxEZ"
      },
      "source": [
        ""
      ],
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "196rBiwTPmZA"
      },
      "source": [
        "3. Chinking\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gl2o8BFkP3lp",
        "outputId": "e1c650d1-5d7a-4598-e045-5b6e5c086893"
      },
      "source": [
        "grammar = r\"\"\"\n",
        "  NP: {<DT|PP\\$>?<JJ>*<NN>}  \n",
        "      {<NNP>+}                \n",
        "\"\"\"\n",
        "cp = nltk.RegexpParser(grammar)\n",
        "sentence = [(\"Rapunzel\", \"NNP\"), (\"let\", \"VBD\"), (\"down\", \"RP\"), \n",
        "                 (\"her\", \"PP$\"), (\"long\", \"JJ\"), (\"golden\", \"JJ\"), (\"hair\", \"NN\")]\n",
        "print(cp.parse(sentence))"
      ],
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(S\n",
            "  (NP Rapunzel/NNP)\n",
            "  let/VBD\n",
            "  down/RP\n",
            "  (NP her/PP$ long/JJ golden/JJ hair/NN))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6kP0xUTTnd9",
        "outputId": "07ada022-f0b4-432a-ba63-d0ae32f66505"
      },
      "source": [
        "nouns = [(\"money\", \"NN\"), (\"market\", \"NN\"), (\"fund\", \"NN\")]\n",
        "grammar = \"NP: {<NN><NN>}  # Chunk two consecutive nouns\"\n",
        "cp = nltk.RegexpParser(grammar)\n",
        "print(cp.parse(nouns))"
      ],
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(S (NP money/NN market/NN) fund/NN)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tn2tMiN0VbxG"
      },
      "source": [
        "4. Named Entity Recognition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135
        },
        "id": "IBEixG42T_cF",
        "outputId": "e8101b8e-28b1-4e20-8df6-3ab153e008fb"
      },
      "source": [
        "import nltk\n",
        "nltk.download('treebank')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "sent = nltk.corpus.treebank.tagged_sents()\n",
        "print(nltk.ne_chunk(sent, binary=True))\n",
        "(S\n",
        " The/DT\n",
        "  (NE U.S./NNP)\n",
        "  is/VBZ\n",
        "  one/CD\n",
        "  \n",
        "  according/VBG\n",
        "  to/TO\n",
        "  (NE Brooke/NNP T./NNP Mossman/NNP)\n",
        ")"
      ],
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-194-33611365e2c1>\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    The/DT\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "budB8LhVWFGb"
      },
      "source": [
        "Relation Extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w07rLf0wWGVA"
      },
      "source": [
        "import nltk\n",
        "nltk.download('ieer')\n",
        "IN = re.compile(r'.*\\bin\\b(?!\\b.+ing)')\n",
        "for doc in nltk.corpus.ieer.parsed_docs('NYT_19980315'):\n",
        " for rel in nltk.sem.extract_rels('ORG', 'LOC', doc,\n",
        "                         corpus='ieer', pattern = IN):\n",
        "  print(nltk.sem.rtuple(rel))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFHuKo3iWkpW"
      },
      "source": [
        "from nltk.corpus import conll2002\n",
        "nltk.download('conll2002')\n",
        "vnv = \"\"\"\n",
        "(\n",
        "is/V|    # 3rd sing present and\n",
        "was/V|   # past forms of the verb zijn ('be')\n",
        "werd/V|  # and also present\n",
        "wordt/V  # past of worden ('become)\n",
        ")\n",
        " .*       # followed by anything\n",
        "van/Prep # followed by van ('of')\n",
        "\"\"\"\n",
        "\n",
        "VAN = re.compile(vnv, re.VERBOSE)\n",
        "for doc in conll2002.chunked_sents('ned.train'):\n",
        " for rel in nltk.sem.extract_rels('PER', 'ORG', doc,\n",
        "                                corpus='conll2002', pattern=VAN):\n",
        "  print(nltk.sem.clause(rel, relsym=\"VAN\"))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}